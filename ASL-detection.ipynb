{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bf4c30-ed5e-4f8d-86fc-9fa4acaedc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python mediapipe numpy pandas matplotlib seaborn tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d079ce-22e3-4550-b3bb-3452e11c316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99169725-7cbb-45ea-98ea-eb7d2784e2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e795cfa1-aecf-4454-9774-fb388a20cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe(frame, hands):\n",
    "    frame = cv2.resize(cv2.flip(frame, 1), (640, 480))\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    image.flags.writeable = False\n",
    "    results = hands.process(image)\n",
    "    image.flags.writeable = True\n",
    "\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc18f9f6-da52-4a9b-8c32-59ff4b5d6391",
   "metadata": {},
   "outputs": [],
   "source": [
    "capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38024b18-102e-498e-b5b7-26efb5b8e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while capture.isOpened():\n",
    "        ret, frame = capture.read()\n",
    "\n",
    "        image, results = mediapipe(frame, hands)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, \n",
    "                    hand_landmarks, \n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                )\n",
    "\n",
    "        cv2.imshow(\"Hand Tracking\", image)\n",
    "\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fcb898-daaf-420e-8ae8-461034bfd8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.multi_hand_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c0fd15f-43be-4e0b-9a9b-2f7a2416d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b361e9e-3416-4cb3-be9c-275f1fa83908",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Dataset/train_data.csv')\n",
    "test = pd.read_csv('Dataset/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ced9d72-c9b6-487c-8e28-06f7246b34fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ver.x0</th>\n",
       "      <th>ver.y0</th>\n",
       "      <th>ver.z0</th>\n",
       "      <th>ver.x1</th>\n",
       "      <th>ver.y1</th>\n",
       "      <th>ver.z1</th>\n",
       "      <th>ver.x2</th>\n",
       "      <th>ver.y2</th>\n",
       "      <th>ver.z2</th>\n",
       "      <th>...</th>\n",
       "      <th>ver.z17</th>\n",
       "      <th>ver.x18</th>\n",
       "      <th>ver.y18</th>\n",
       "      <th>ver.z18</th>\n",
       "      <th>ver.x19</th>\n",
       "      <th>ver.y19</th>\n",
       "      <th>ver.z19</th>\n",
       "      <th>ver.x20</th>\n",
       "      <th>ver.y20</th>\n",
       "      <th>ver.z20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.278411</td>\n",
       "      <td>0.695334</td>\n",
       "      <td>-6.762847e-07</td>\n",
       "      <td>0.200128</td>\n",
       "      <td>0.620533</td>\n",
       "      <td>-0.022475</td>\n",
       "      <td>0.142370</td>\n",
       "      <td>0.516582</td>\n",
       "      <td>-0.040151</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049513</td>\n",
       "      <td>0.365731</td>\n",
       "      <td>0.458294</td>\n",
       "      <td>-0.073240</td>\n",
       "      <td>0.357022</td>\n",
       "      <td>0.511900</td>\n",
       "      <td>-0.059459</td>\n",
       "      <td>0.346693</td>\n",
       "      <td>0.564412</td>\n",
       "      <td>-0.040863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0.579226</td>\n",
       "      <td>0.760085</td>\n",
       "      <td>-1.479179e-06</td>\n",
       "      <td>0.411217</td>\n",
       "      <td>0.680030</td>\n",
       "      <td>-0.040085</td>\n",
       "      <td>0.265983</td>\n",
       "      <td>0.565985</td>\n",
       "      <td>-0.118771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242286</td>\n",
       "      <td>0.591494</td>\n",
       "      <td>0.576435</td>\n",
       "      <td>-0.280686</td>\n",
       "      <td>0.557463</td>\n",
       "      <td>0.594451</td>\n",
       "      <td>-0.267542</td>\n",
       "      <td>0.534894</td>\n",
       "      <td>0.644566</td>\n",
       "      <td>-0.263740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0.479878</td>\n",
       "      <td>0.789794</td>\n",
       "      <td>-1.101431e-06</td>\n",
       "      <td>0.379517</td>\n",
       "      <td>0.716278</td>\n",
       "      <td>-0.031272</td>\n",
       "      <td>0.307061</td>\n",
       "      <td>0.580528</td>\n",
       "      <td>-0.051447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067705</td>\n",
       "      <td>0.580279</td>\n",
       "      <td>0.515611</td>\n",
       "      <td>-0.106108</td>\n",
       "      <td>0.559661</td>\n",
       "      <td>0.600459</td>\n",
       "      <td>-0.090427</td>\n",
       "      <td>0.554961</td>\n",
       "      <td>0.667288</td>\n",
       "      <td>-0.067013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>0.475106</td>\n",
       "      <td>0.804069</td>\n",
       "      <td>-1.105380e-06</td>\n",
       "      <td>0.369806</td>\n",
       "      <td>0.720176</td>\n",
       "      <td>-0.034797</td>\n",
       "      <td>0.296779</td>\n",
       "      <td>0.589539</td>\n",
       "      <td>-0.059023</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075889</td>\n",
       "      <td>0.574916</td>\n",
       "      <td>0.524177</td>\n",
       "      <td>-0.114318</td>\n",
       "      <td>0.557065</td>\n",
       "      <td>0.611504</td>\n",
       "      <td>-0.097624</td>\n",
       "      <td>0.546631</td>\n",
       "      <td>0.681055</td>\n",
       "      <td>-0.074528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>0.466990</td>\n",
       "      <td>0.802180</td>\n",
       "      <td>-1.071714e-06</td>\n",
       "      <td>0.365610</td>\n",
       "      <td>0.740132</td>\n",
       "      <td>-0.033263</td>\n",
       "      <td>0.292247</td>\n",
       "      <td>0.604434</td>\n",
       "      <td>-0.052462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.070841</td>\n",
       "      <td>0.566635</td>\n",
       "      <td>0.533698</td>\n",
       "      <td>-0.108298</td>\n",
       "      <td>0.545575</td>\n",
       "      <td>0.618803</td>\n",
       "      <td>-0.092145</td>\n",
       "      <td>0.540315</td>\n",
       "      <td>0.682023</td>\n",
       "      <td>-0.069202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label    ver.x0    ver.y0        ver.z0    ver.x1    ver.y1    ver.z1  \\\n",
       "0     A  0.278411  0.695334 -6.762847e-07  0.200128  0.620533 -0.022475   \n",
       "1     A  0.579226  0.760085 -1.479179e-06  0.411217  0.680030 -0.040085   \n",
       "2     A  0.479878  0.789794 -1.101431e-06  0.379517  0.716278 -0.031272   \n",
       "3     A  0.475106  0.804069 -1.105380e-06  0.369806  0.720176 -0.034797   \n",
       "4     A  0.466990  0.802180 -1.071714e-06  0.365610  0.740132 -0.033263   \n",
       "\n",
       "     ver.x2    ver.y2    ver.z2  ...   ver.z17   ver.x18   ver.y18   ver.z18  \\\n",
       "0  0.142370  0.516582 -0.040151  ... -0.049513  0.365731  0.458294 -0.073240   \n",
       "1  0.265983  0.565985 -0.118771  ... -0.242286  0.591494  0.576435 -0.280686   \n",
       "2  0.307061  0.580528 -0.051447  ... -0.067705  0.580279  0.515611 -0.106108   \n",
       "3  0.296779  0.589539 -0.059023  ... -0.075889  0.574916  0.524177 -0.114318   \n",
       "4  0.292247  0.604434 -0.052462  ... -0.070841  0.566635  0.533698 -0.108298   \n",
       "\n",
       "    ver.x19   ver.y19   ver.z19   ver.x20   ver.y20   ver.z20  \n",
       "0  0.357022  0.511900 -0.059459  0.346693  0.564412 -0.040863  \n",
       "1  0.557463  0.594451 -0.267542  0.534894  0.644566 -0.263740  \n",
       "2  0.559661  0.600459 -0.090427  0.554961  0.667288 -0.067013  \n",
       "3  0.557065  0.611504 -0.097624  0.546631  0.681055 -0.074528  \n",
       "4  0.545575  0.618803 -0.092145  0.540315  0.682023 -0.069202  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6c8417-0b51-4bc8-9535-f56c11a39708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ver.x0</th>\n",
       "      <th>ver.y0</th>\n",
       "      <th>ver.z0</th>\n",
       "      <th>ver.x1</th>\n",
       "      <th>ver.y1</th>\n",
       "      <th>ver.z1</th>\n",
       "      <th>ver.x2</th>\n",
       "      <th>ver.y2</th>\n",
       "      <th>ver.z2</th>\n",
       "      <th>...</th>\n",
       "      <th>ver.z17</th>\n",
       "      <th>ver.x18</th>\n",
       "      <th>ver.y18</th>\n",
       "      <th>ver.z18</th>\n",
       "      <th>ver.x19</th>\n",
       "      <th>ver.y19</th>\n",
       "      <th>ver.z19</th>\n",
       "      <th>ver.x20</th>\n",
       "      <th>ver.y20</th>\n",
       "      <th>ver.z20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>0.468974</td>\n",
       "      <td>0.957347</td>\n",
       "      <td>8.264763e-07</td>\n",
       "      <td>0.334997</td>\n",
       "      <td>0.871521</td>\n",
       "      <td>-0.059660</td>\n",
       "      <td>0.252024</td>\n",
       "      <td>0.746197</td>\n",
       "      <td>-0.078749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.557779</td>\n",
       "      <td>0.479014</td>\n",
       "      <td>-0.010508</td>\n",
       "      <td>0.554430</td>\n",
       "      <td>0.399632</td>\n",
       "      <td>-0.020901</td>\n",
       "      <td>0.554333</td>\n",
       "      <td>0.327857</td>\n",
       "      <td>-0.031532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>0.389900</td>\n",
       "      <td>0.802690</td>\n",
       "      <td>-4.815158e-07</td>\n",
       "      <td>0.295742</td>\n",
       "      <td>0.703891</td>\n",
       "      <td>-0.037011</td>\n",
       "      <td>0.234400</td>\n",
       "      <td>0.600398</td>\n",
       "      <td>-0.058510</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015473</td>\n",
       "      <td>0.690986</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>-0.041385</td>\n",
       "      <td>0.719852</td>\n",
       "      <td>0.438441</td>\n",
       "      <td>-0.056521</td>\n",
       "      <td>0.723234</td>\n",
       "      <td>0.364735</td>\n",
       "      <td>-0.064935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G</td>\n",
       "      <td>0.396125</td>\n",
       "      <td>0.764175</td>\n",
       "      <td>-3.180436e-07</td>\n",
       "      <td>0.390238</td>\n",
       "      <td>0.598494</td>\n",
       "      <td>-0.018371</td>\n",
       "      <td>0.436514</td>\n",
       "      <td>0.499410</td>\n",
       "      <td>-0.020791</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028913</td>\n",
       "      <td>0.669916</td>\n",
       "      <td>0.721085</td>\n",
       "      <td>-0.064301</td>\n",
       "      <td>0.587629</td>\n",
       "      <td>0.739817</td>\n",
       "      <td>-0.035708</td>\n",
       "      <td>0.537452</td>\n",
       "      <td>0.751202</td>\n",
       "      <td>-0.001966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>0.698550</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>-8.286916e-07</td>\n",
       "      <td>0.549498</td>\n",
       "      <td>0.726644</td>\n",
       "      <td>-0.036801</td>\n",
       "      <td>0.465512</td>\n",
       "      <td>0.568181</td>\n",
       "      <td>-0.065155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.060483</td>\n",
       "      <td>0.758317</td>\n",
       "      <td>0.243623</td>\n",
       "      <td>-0.097302</td>\n",
       "      <td>0.748477</td>\n",
       "      <td>0.144045</td>\n",
       "      <td>-0.098005</td>\n",
       "      <td>0.737958</td>\n",
       "      <td>0.050565</td>\n",
       "      <td>-0.085202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>J</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.717258</td>\n",
       "      <td>-8.534749e-07</td>\n",
       "      <td>0.258111</td>\n",
       "      <td>0.584270</td>\n",
       "      <td>-0.047144</td>\n",
       "      <td>0.309129</td>\n",
       "      <td>0.440646</td>\n",
       "      <td>-0.065515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004593</td>\n",
       "      <td>0.632797</td>\n",
       "      <td>0.460989</td>\n",
       "      <td>-0.035958</td>\n",
       "      <td>0.689990</td>\n",
       "      <td>0.406403</td>\n",
       "      <td>-0.043470</td>\n",
       "      <td>0.744364</td>\n",
       "      <td>0.348788</td>\n",
       "      <td>-0.039284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  label    ver.x0    ver.y0        ver.z0    ver.x1    ver.y1    ver.z1  \\\n",
       "0     B  0.468974  0.957347  8.264763e-07  0.334997  0.871521 -0.059660   \n",
       "1     F  0.389900  0.802690 -4.815158e-07  0.295742  0.703891 -0.037011   \n",
       "2     G  0.396125  0.764175 -3.180436e-07  0.390238  0.598494 -0.018371   \n",
       "3     I  0.698550  0.819186 -8.286916e-07  0.549498  0.726644 -0.036801   \n",
       "4     J  0.302200  0.717258 -8.534749e-07  0.258111  0.584270 -0.047144   \n",
       "\n",
       "     ver.x2    ver.y2    ver.z2  ...   ver.z17   ver.x18   ver.y18   ver.z18  \\\n",
       "0  0.252024  0.746197 -0.078749  ...  0.001565  0.557779  0.479014 -0.010508   \n",
       "1  0.234400  0.600398 -0.058510  ... -0.015473  0.690986  0.515100 -0.041385   \n",
       "2  0.436514  0.499410 -0.020791  ... -0.028913  0.669916  0.721085 -0.064301   \n",
       "3  0.465512  0.568181 -0.065155  ... -0.060483  0.758317  0.243623 -0.097302   \n",
       "4  0.309129  0.440646 -0.065515  ... -0.004593  0.632797  0.460989 -0.035958   \n",
       "\n",
       "    ver.x19   ver.y19   ver.z19   ver.x20   ver.y20   ver.z20  \n",
       "0  0.554430  0.399632 -0.020901  0.554333  0.327857 -0.031532  \n",
       "1  0.719852  0.438441 -0.056521  0.723234  0.364735 -0.064935  \n",
       "2  0.587629  0.739817 -0.035708  0.537452  0.751202 -0.001966  \n",
       "3  0.748477  0.144045 -0.098005  0.737958  0.050565 -0.085202  \n",
       "4  0.689990  0.406403 -0.043470  0.744364  0.348788 -0.039284  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba8b3e7-c221-49d1-8c20-e8ea32595514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train['label'].values\n",
    "unique_val = np.array(labels)\n",
    "np.unique(unique_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dafb2d09-6e76-45e5-8157-d45dd4606b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAGdCAYAAADzOWwgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvYklEQVR4nO3de1SU9d7//9cAclAERQVE0SjdHsq0NI1qqyiGpt1arMq9qShZurehZfZVo+2hNDW10q15LI93Wu1qa8WdpKGoJYFpVqaZlaapA5UCioko1++PFvNzPMUMI4x+no+1rrWcz/W53vO+EIbXXIfBZlmWJQAAAIP5VHcDAAAA1Y1ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwnl91N3AlKCsr06FDh1S7dm3ZbLbqbgcAAFSAZVk6duyYoqKi5ONz6WNABKIKOHTokKKjo6u7DQAA4IYDBw6ocePGl5xDIKqA2rVrS/rjCxoSElLN3QAAgIooKipSdHS04/f4pRCIKqD8NFlISAiBCACAK0xFLnfhomoAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMF61BqKNGzfq7rvvVlRUlGw2m1atWuW03rIsjR07Vg0bNlRQUJDi4+O1Z88epzlHjhxRUlKSQkJCVKdOHaWkpOj48eNOc7766iv99a9/VWBgoKKjozV16tTLvWsAAOAKUq2BqLi4WG3bttXs2bMvuH7q1KmaOXOm5s2bp5ycHNWqVUsJCQk6efKkY05SUpK++eYbrV27Vunp6dq4caMGDRrkWF9UVKQ777xTTZs21datWzVt2jQ9++yzWrBgwWXfPwAAcIWwvIQka+XKlY7HZWVlVmRkpDVt2jTHWEFBgRUQEGC98cYblmVZ1s6dOy1J1pYtWxxzVq9ebdlsNuvgwYOWZVnWnDlzrLp161olJSWOOaNGjbJatGhR4d4KCwstSVZhYaG7uwcAAKqYK7+/vfYaor1798putys+Pt4xFhoaqk6dOik7O1uSlJ2drTp16qhDhw6OOfHx8fLx8VFOTo5jTufOneXv7++Yk5CQoN27d+vo0aMXfO6SkhIVFRU5LQAA4OrlV90NXIzdbpckRUREOI1HREQ41tntdoWHhzut9/PzU1hYmNOcmJiY82qUr6tbt+55zz158mQ999xzntkRoBq1H7HM7W23TnvYg50AgHfz2kBUndLS0jR8+HDH46KiIkVHR1djRzAJIQYAqp7XBqLIyEhJUl5enho2bOgYz8vLU7t27Rxz8vPznbY7ffq0jhw54tg+MjJSeXl5TnPKH5fPOVdAQIACAgI8sh8AAJjkSn1T57XXEMXExCgyMlKZmZmOsaKiIuXk5Cg2NlaSFBsbq4KCAm3dutUxZ926dSorK1OnTp0cczZu3KjS0lLHnLVr16pFixYXPF0GAADMU61HiI4fP67vv//e8Xjv3r3avn27wsLC1KRJEw0bNkzPP/+8mjdvrpiYGI0ZM0ZRUVHq16+fJKlVq1bq2bOnBg4cqHnz5qm0tFRDhgxR//79FRUVJUn6+9//rueee04pKSkaNWqUduzYoX//+9+aPn16dewycMW6Ut/1AUBFVGsg+vzzzxUXF+d4XH7dTnJyspYsWaKRI0equLhYgwYNUkFBge644w5lZGQoMDDQsc3y5cs1ZMgQde/eXT4+PkpMTNTMmTMd60NDQ7VmzRqlpqaqffv2ql+/vsaOHev0WUUAAMBs1RqIunbtKsuyLrreZrNp/PjxGj9+/EXnhIWFacWKFZd8nhtvvFGbNm1yu08AAHB189priAAAAKoKgQgAABjPa2+7By43LhIGAJTjCBEAADAegQgAABiPQAQAAIxHIAIAAMbjomoAgFfgRgdUJwIR4AG8kAPAlY1ABACGIcAD5+MaIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA43HbPQAA8EpV+RERHCECAADGIxABAADjEYgAAIDxCEQAAMB4XFQNAMAViL9J51kcIQIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI/PIQJQ5Uz4/JTK7KN05ewncLXgCBEAADAegQgAABiPQAQAAIzHNUQAgKuOCdepwbMIRAAAtxE8cLXglBkAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAONxlxkAAJfAnXRmIBDhgngBAACYhFNmAADAeAQiAABgPAIRAAAwHoEIAAAYj4uqAQCoItyw4r04QgQAAIxHIAIAAMbjlBmuKBxuBgDP47WVI0QAAAAEIgAAAAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8rw5EZ86c0ZgxYxQTE6OgoCBdd911mjBhgizLcsyxLEtjx45Vw4YNFRQUpPj4eO3Zs8epzpEjR5SUlKSQkBDVqVNHKSkpOn78eFXvDgAA8FJeHYimTJmiuXPn6pVXXtGuXbs0ZcoUTZ06VbNmzXLMmTp1qmbOnKl58+YpJydHtWrVUkJCgk6ePOmYk5SUpG+++UZr165Venq6Nm7cqEGDBlXHLgEAAC/k1X/cdfPmzerbt6969+4tSbrmmmv0xhtvKDc3V9IfR4dmzJih0aNHq2/fvpKkZcuWKSIiQqtWrVL//v21a9cuZWRkaMuWLerQoYMkadasWbrrrrv04osvKioqqnp2DgAAeA2vPkJ02223KTMzU999950k6csvv9Qnn3yiXr16SZL27t0ru92u+Ph4xzahoaHq1KmTsrOzJUnZ2dmqU6eOIwxJUnx8vHx8fJSTk3PB5y0pKVFRUZHTAgAArl5efYTo6aefVlFRkVq2bClfX1+dOXNGEydOVFJSkiTJbrdLkiIiIpy2i4iIcKyz2+0KDw93Wu/n56ewsDDHnHNNnjxZzz33nKd3BwAAeCmvPkL0n//8R8uXL9eKFSu0bds2LV26VC+++KKWLl16WZ83LS1NhYWFjuXAgQOX9fkAAED18uojRCNGjNDTTz+t/v37S5LatGmjn376SZMnT1ZycrIiIyMlSXl5eWrYsKFju7y8PLVr106SFBkZqfz8fKe6p0+f1pEjRxzbnysgIEABAQGXYY8AAIA38uojRCdOnJCPj3OLvr6+KisrkyTFxMQoMjJSmZmZjvVFRUXKyclRbGysJCk2NlYFBQXaunWrY866detUVlamTp06VcFeAAAAb+fVR4juvvtuTZw4UU2aNNH111+vL774Qi+//LIGDBggSbLZbBo2bJief/55NW/eXDExMRozZoyioqLUr18/SVKrVq3Us2dPDRw4UPPmzVNpaamGDBmi/v37c4cZAACQ5OWBaNasWRozZowee+wx5efnKyoqSv/4xz80duxYx5yRI0equLhYgwYNUkFBge644w5lZGQoMDDQMWf58uUaMmSIunfvLh8fHyUmJmrmzJnVsUsAAMALeXUgql27tmbMmKEZM2ZcdI7NZtP48eM1fvz4i84JCwvTihUrLkOHAADgauDV1xABAABUBQIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOP5VXcD8Iz2I5ZVavut0x72UCcAAFx5OEIEAACMRyACAADGIxABAADjcQ0RLrvKXN/EtU0AgKrAESIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHh8MCMAeDn+eDNw+XGECAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8bjLrBpx5wgAAN6BI0QAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPL/qbgAAKqP9iGVub7t12sMe7ATAlYwjRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxvP6QHTw4EE9+OCDqlevnoKCgtSmTRt9/vnnjvWWZWns2LFq2LChgoKCFB8frz179jjVOHLkiJKSkhQSEqI6deooJSVFx48fr+pdAQAAXsqrA9HRo0d1++23q0aNGlq9erV27typl156SXXr1nXMmTp1qmbOnKl58+YpJydHtWrVUkJCgk6ePOmYk5SUpG+++UZr165Venq6Nm7cqEGDBlXHLgEAAC/k1R/MOGXKFEVHR2vx4sWOsZiYGMe/LcvSjBkzNHr0aPXt21eStGzZMkVERGjVqlXq37+/du3apYyMDG3ZskUdOnSQJM2aNUt33XWXXnzxRUVFRVXtTgEAAK/j1UeI3n//fXXo0EH33XefwsPDddNNN+nVV191rN+7d6/sdrvi4+MdY6GhoerUqZOys7MlSdnZ2apTp44jDElSfHy8fHx8lJOTc8HnLSkpUVFRkdMCAACuXl4diH788UfNnTtXzZs310cffaTBgwfr8ccf19KlSyVJdrtdkhQREeG0XUREhGOd3W5XeHi403o/Pz+FhYU55pxr8uTJCg0NdSzR0dGe3jUAAOBFvDoQlZWV6eabb9akSZN00003adCgQRo4cKDmzZt3WZ83LS1NhYWFjuXAgQOX9fkAAED18upA1LBhQ7Vu3dpprFWrVtq/f78kKTIyUpKUl5fnNCcvL8+xLjIyUvn5+U7rT58+rSNHjjjmnCsgIEAhISFOCwAAuHp5dSC6/fbbtXv3bqex7777Tk2bNpX0xwXWkZGRyszMdKwvKipSTk6OYmNjJUmxsbEqKCjQ1q1bHXPWrVunsrIyderUqQr2AgAAeDuvvsvsySef1G233aZJkybp/vvvV25urhYsWKAFCxZIkmw2m4YNG6bnn39ezZs3V0xMjMaMGaOoqCj169dP0h9HlHr27Ok41VZaWqohQ4aof//+3GEGAAAkeXkguuWWW7Ry5UqlpaVp/PjxiomJ0YwZM5SUlOSYM3LkSBUXF2vQoEEqKCjQHXfcoYyMDAUGBjrmLF++XEOGDFH37t3l4+OjxMREzZw5szp2CQAAeCGvDkSS1KdPH/Xp0+ei6202m8aPH6/x48dfdE5YWJhWrFhxOdoDAABXAa++hggAAKAqEIgAAIDx3ApE3bp1U0FBwXnjRUVF6tatW2V7AgAAqFJuXUOUlZWlU6dOnTd+8uRJbdq0qdJNebP2I5ZVavut0x72UCcAAMBTXApEX331lePfO3fudPrTF2fOnFFGRoYaNWrkue4AAACqgEuBqF27drLZbLLZbBc8NRYUFKRZs2Z5rDkAAICq4FIg2rt3ryzL0rXXXqvc3Fw1aNDAsc7f31/h4eHy9fX1eJMAAACXk0uBqPxPZpSVlV2WZgAAAKqD2x/MuGfPHq1fv175+fnnBaSxY8dWujEAAICq4lYgevXVVzV48GDVr19fkZGRstlsjnU2m41ABAAArihuBaLnn39eEydO1KhRozzdDwAAQJVz64MZjx49qvvuu8/TvQAAAFQLtwLRfffdpzVr1ni6FwAAgGrh1imzZs2aacyYMfrss8/Upk0b1ahRw2n9448/7pHmAAAAqoJbgWjBggUKDg7Whg0btGHDBqd1NpuNQAQAAK4obgWivXv3eroPAACAauPWNUQAAABXE7eOEA0YMOCS6xctWuRWMwAAANXBrUB09OhRp8elpaXasWOHCgoKLvhHXwEAALyZW4Fo5cqV542VlZVp8ODBuu666yrdFAAAQFXy2DVEPj4+Gj58uKZPn+6pkgAAAFXCoxdV//DDDzp9+rQnSwIAAFx2bp0yGz58uNNjy7J0+PBh/d///Z+Sk5M90hgAAEBVcSsQffHFF06PfXx81KBBA7300kt/egcaAACAt3ErEK1fv97TfQAAAFQbtwJRuV9++UW7d++WJLVo0UINGjTwSFMAAABVya2LqouLizVgwAA1bNhQnTt3VufOnRUVFaWUlBSdOHHC0z0CAABcVm4FouHDh2vDhg364IMPVFBQoIKCAr333nvasGGDnnrqKU/3CAAAcFm5dcrs3Xff1TvvvKOuXbs6xu666y4FBQXp/vvv19y5cz3VHwAAwGXn1hGiEydOKCIi4rzx8PBwTpkBAIArjluBKDY2VuPGjdPJkycdY7///ruee+45xcbGeqw5AACAquDWKbMZM2aoZ8+eaty4sdq2bStJ+vLLLxUQEKA1a9Z4tEEAAIDLza1A1KZNG+3Zs0fLly/Xt99+K0n629/+pqSkJAUFBXm0QQAAgMvNrUA0efJkRUREaODAgU7jixYt0i+//KJRo0Z5pDkAAICq4NY1RPPnz1fLli3PG7/++us1b968SjcFAABQldwKRHa7XQ0bNjxvvEGDBjp8+HClmwIAAKhKbgWi6Ohoffrpp+eNf/rpp4qKiqp0UwAAAFXJrWuIBg4cqGHDhqm0tFTdunWTJGVmZmrkyJF8UjUAALjiuBWIRowYod9++02PPfaYTp06JUkKDAzUqFGjlJaW5tEGAQAALje3ApHNZtOUKVM0ZswY7dq1S0FBQWrevLkCAgI83R8AAMBl51YgKhccHKxbbrnFU70AAABUC7cuqgYAALiaEIgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8a6oQPTCCy/IZrNp2LBhjrGTJ08qNTVV9erVU3BwsBITE5WXl+e03f79+9W7d2/VrFlT4eHhGjFihE6fPl3F3QMAAG91xQSiLVu2aP78+brxxhudxp988kl98MEHevvtt7VhwwYdOnRI9957r2P9mTNn1Lt3b506dUqbN2/W0qVLtWTJEo0dO7aqdwEAAHipKyIQHT9+XElJSXr11VdVt25dx3hhYaEWLlyol19+Wd26dVP79u21ePFibd68WZ999pkkac2aNdq5c6def/11tWvXTr169dKECRM0e/ZsnTp1qrp2CQAAeJErIhClpqaqd+/eio+PdxrfunWrSktLncZbtmypJk2aKDs7W5KUnZ2tNm3aKCIiwjEnISFBRUVF+uabby74fCUlJSoqKnJaAADA1cuvuhv4M2+++aa2bdumLVu2nLfObrfL399fderUcRqPiIiQ3W53zDk7DJWvL193IZMnT9Zzzz3nge4BAMCVwKuPEB04cEBPPPGEli9frsDAwCp73rS0NBUWFjqWAwcOVNlzAwCAqufVgWjr1q3Kz8/XzTffLD8/P/n5+WnDhg2aOXOm/Pz8FBERoVOnTqmgoMBpu7y8PEVGRkqSIiMjz7vrrPxx+ZxzBQQEKCQkxGkBAABXL68+Zda9e3d9/fXXTmOPPvqoWrZsqVGjRik6Olo1atRQZmamEhMTJUm7d+/W/v37FRsbK0mKjY3VxIkTlZ+fr/DwcEnS2rVrFRISotatW1ftDgHwau1HLKvU9lunPeyhTgBUNa8ORLVr19YNN9zgNFarVi3Vq1fPMZ6SkqLhw4crLCxMISEhGjp0qGJjY3XrrbdKku688061bt1aDz30kKZOnSq73a7Ro0crNTVVAQEBVb5PAADA+3h1IKqI6dOny8fHR4mJiSopKVFCQoLmzJnjWO/r66v09HQNHjxYsbGxqlWrlpKTkzV+/Phq7BoAAHiTKy4QZWVlOT0ODAzU7NmzNXv27Itu07RpU3344YeXuTMAAHCl8uqLqgEAAKoCgQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxvPqQDR58mTdcsstql27tsLDw9WvXz/t3r3bac7JkyeVmpqqevXqKTg4WImJicrLy3Oas3//fvXu3Vs1a9ZUeHi4RowYodOnT1flrgAAAC/m1YFow4YNSk1N1Weffaa1a9eqtLRUd955p4qLix1znnzySX3wwQd6++23tWHDBh06dEj33nuvY/2ZM2fUu3dvnTp1Sps3b9bSpUu1ZMkSjR07tjp2CQAAeCG/6m7gUjIyMpweL1myROHh4dq6das6d+6swsJCLVy4UCtWrFC3bt0kSYsXL1arVq302Wef6dZbb9WaNWu0c+dOffzxx4qIiFC7du00YcIEjRo1Ss8++6z8/f2rY9cAAIAX8eojROcqLCyUJIWFhUmStm7dqtLSUsXHxzvmtGzZUk2aNFF2drYkKTs7W23atFFERIRjTkJCgoqKivTNN99c8HlKSkpUVFTktAAAgKvXFROIysrKNGzYMN1+++264YYbJEl2u13+/v6qU6eO09yIiAjZ7XbHnLPDUPn68nUXMnnyZIWGhjqW6OhoD+8NAADwJldMIEpNTdWOHTv05ptvXvbnSktLU2FhoWM5cODAZX9OAABQfbz6GqJyQ4YMUXp6ujZu3KjGjRs7xiMjI3Xq1CkVFBQ4HSXKy8tTZGSkY05ubq5TvfK70MrnnCsgIEABAQEe3gsAAOCtvPoIkWVZGjJkiFauXKl169YpJibGaX379u1Vo0YNZWZmOsZ2796t/fv3KzY2VpIUGxurr7/+Wvn5+Y45a9euVUhIiFq3bl01OwIAALyaVx8hSk1N1YoVK/Tee++pdu3ajmt+QkNDFRQUpNDQUKWkpGj48OEKCwtTSEiIhg4dqtjYWN16662SpDvvvFOtW7fWQw89pKlTp8put2v06NFKTU3lKBAAAJDk5YFo7ty5kqSuXbs6jS9evFiPPPKIJGn69Ony8fFRYmKiSkpKlJCQoDlz5jjm+vr6Kj09XYMHD1ZsbKxq1aql5ORkjR8/vqp2AwAAeDmvDkSWZf3pnMDAQM2ePVuzZ8++6JymTZvqww8/9GRrAADgKuLV1xABAABUBQIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABiPQAQAAIxHIAIAAMYjEAEAAOMRiAAAgPEIRAAAwHgEIgAAYDwCEQAAMB6BCAAAGI9ABAAAjEcgAgAAxiMQAQAA4xGIAACA8QhEAADAeAQiAABgPAIRAAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADAegQgAABjPqEA0e/ZsXXPNNQoMDFSnTp2Um5tb3S0BAAAvYEwgeuuttzR8+HCNGzdO27ZtU9u2bZWQkKD8/Pzqbg0AAFQzYwLRyy+/rIEDB+rRRx9V69atNW/ePNWsWVOLFi2q7tYAAEA186vuBqrCqVOntHXrVqWlpTnGfHx8FB8fr+zs7PPml5SUqKSkxPG4sLBQklRUVKQzJb9XqpeioiLHv721VmXrUYtaJtY6t5631qpsPWpR60qqVV7Psqw/38AywMGDBy1J1ubNm53GR4wYYXXs2PG8+ePGjbMksbCwsLCwsFwFy4EDB/40KxhxhMhVaWlpGj58uONxWVmZjhw5onr16slms110u6KiIkVHR+vAgQMKCQmpVA/UotaV1Bu1qEUtfr69sZZlWTp27JiioqL+tJ4Rgah+/fry9fVVXl6e03heXp4iIyPPmx8QEKCAgACnsTp16lT4+UJCQjzyw0EtalVFPWpRi1reU8vT9aglhYaGVqiOERdV+/v7q3379srMzHSMlZWVKTMzU7GxsdXYGQAA8AZGHCGSpOHDhys5OVkdOnRQx44dNWPGDBUXF+vRRx+t7tYAAEA1MyYQPfDAA/rll180duxY2e12tWvXThkZGYqIiPDYcwQEBGjcuHHnnW6jFrU8UcvT9ahFLWp5Ty1P16OW62yWVZF70QAAAK5eRlxDBAAAcCkEIgAAYDwCEQAAMB6BCAAAGI9A5CHZ2dny9fVV7969K1XnkUcekc1mcyz16tVTz5499dVXX7lVz263a+jQobr22msVEBCg6Oho3X333U6fyeRKTzVq1FBERIR69OihRYsWqayszOWezt3H8qVnz54u17pUve+//97lWna7XU888YSaNWumwMBARURE6Pbbb9fcuXN14sQJl3rq16/feeNZWVmy2WwqKChwubdL1a2uWheq8c477ygwMFAvvfRStfRjs9n0z3/+87x1qampstlseuSRR1yu98ILLziNr1q16pKfWn8xBw4c0IABAxQVFSV/f381bdpUTzzxhH777TeXa539fe/v769mzZpp/PjxOn36tMu1POnc14uYmBiNHDlSJ0+edKveL7/8osGDB6tJkyYKCAhQZGSkEhIS9Omnn1a4xoVeH85enn32WZd66tq1q4YNG3be+JIlS1z6EN+77777oq97mzZtks1m+9PX/nnz5ql27dpO/+/Hjx9XjRo11LVrV6e55a8/P/zwwyVrnjlzRrfddpvuvfdep/HCwkJFR0frX//61yW3P5dlWYqPj1dCQsJ56+bMmaM6dero559/rlCt8n242BIXF+dSb2cjEHnIwoULNXToUG3cuFGHDh2qVK2ePXvq8OHDOnz4sDIzM+Xn56c+ffq4XGffvn1q37691q1bp2nTpunrr79WRkaG4uLilJqa6lZP+/bt0+rVqxUXF6cnnnhCffr0cesF+Ox9LF/eeOMNl+tcql5MTIxLNX788UfddNNNWrNmjSZNmqQvvvhC2dnZGjlypNLT0/Xxxx+73Z8pXnvtNSUlJWnu3Ll66qmnqqWH6Ohovfnmm/r99///j0KePHlSK1asUJMmTVyuFxgYqClTpujo0aOV6uvHH39Uhw4dtGfPHr3xxhv6/vvvNW/ePMcHxB45csTlmuXf93v27NFTTz2lZ599VtOmTXO5jieD2tl9/fjjj5o+fbrmz5+vcePGuVUrMTFRX3zxhZYuXarvvvtO77//vrp27epSb2e/LsyYMUMhISFOY//v//0/t3qrrJSUFK1du/aCYWDx4sXq0KGDbrzxxkvWiIuL0/Hjx/X55587xjZt2qTIyEjl5OQ4BdH169erSZMmuu666y5Z09fXV0uWLFFGRoaWL1/uGB86dKjCwsJc/r+02WxavHixcnJyNH/+fMf43r17NXLkSM2aNUuNGzeuUK3bbrvtvNf6w4cPa/78+bLZbHrsscdc6s2JR/56quGOHTtmBQcHW99++631wAMPWBMnTnS7VnJystW3b1+nsU2bNlmSrPz8fJdq9erVy2rUqJF1/Pjx89YdPXq0Uj1ZlmVlZmZakqxXX33Vpb4uVs9dnqqXkJBgNW7c+IJfL8uyrLKyskr3tH79ekuSS1//itStrlpn15gyZYoVGBho/fe//632fm644Qbr9ddfd4wvX77cuvHGG62+fftaycnJLtXr06eP1bJlS2vEiBGO8ZUrV1quvnz27NnTaty4sXXixAmn8cOHD1s1a9a0/vnPf7pU70Jfrx49eli33nqrS3V++OEHKzw83LrjjjusrKws66effrI+/PBD6/rrr7eaN29u/fbbb5Xu695777Vuuukml+pY1h+vU5KsrKwsl7e9mMWLF1uhoaGVqtGlSxfriSeeqHTt0tJSKyIiwpowYYLTePnvlLlz51aoTsOGDa3Jkyc7Ho8cOdJKTU21WrVqZa1fv94x3rlzZ5e+///9739bdevWtQ4dOmStWrXKqlGjhrV9+/YKb3+uJUuWWMHBwdaPP/5olZWVWXFxcdY999zjdr1yO3futGrXrm3961//qlQdjhB5wH/+8x+1bNlSLVq00IMPPqhFixbJ8tDHOx0/flyvv/66mjVrpnr16lV4uyNHjigjI0OpqamqVavWeetdOax7Md26dVPbtm313//+t9K1qttvv/2mNWvWXPTrJcmtUySmGDVqlCZMmKD09HTdc8891d2OBgwYoMWLFzseL1q0yO1Ppff19dWkSZM0a9asCh/WP9eRI0f00Ucf6bHHHlNQUJDTusjISCUlJemtt96q9OtGUFCQTp065dI2qamp8vf315o1a9SlSxc1adJEvXr10scff6yDBw+6fHrkXDt27NDmzZvl7+/v8rbBwcEKDg7WqlWrVFJSUqk+vJGfn58efvhhLVmyxOn//u2339aZM2f0t7/9rUJ14uLitH79esfj9evXq2vXrurSpYtj/Pfff1dOTo5Lp5SGDh2qtm3b6qGHHtKgQYM0duxYtW3btsLbnys5OVndu3fXgAED9Morr2jHjh1OR4zcUVBQoL59+6pr166aMGFCpWoRiDxg4cKFevDBByX9cai4sLBQGzZscLteenq644Wgdu3aev/99/XWW2/Jx6fi/13ff/+9LMtSy5Yt3e6jIlq2bKl9+/a5vN3Z+1i+TJo0ye0+zq133333ubR9+derRYsWTuP169d31Bw1alSlegoODlavXr1cqnElWL16taZOnar33ntP3bt3r+52JEkPPvigPvnkE/3000/66aef9Omnnzp+Rt1xzz33qF27dm6f9tmzZ48sy1KrVq0uuL5Vq1Y6evSofvnlF7fqW5aljz/+WB999JG6detW4e0uV1Ar/94PDAxUmzZtlJ+frxEjRrhUQ/ojMCxZskRLly5VnTp1dPvtt+uZZ55x+5pKbzRgwAD98MMPTr8zFi9erMTExAr/UdK4uDh9+umnOn36tI4dO6YvvvhCXbp0UefOnZWVlSXpj+tcS0pKXApENptNc+fOVWZmpiIiIvT000+7tG8XsmDBAu3YsUPDhg3TggUL1KBBA7drlZWV6e9//7v8/Py0fPnySr9pNeZPd1wuu3fvVm5urlauXCnpjx/gBx54QAsXLjzvgraKiouL09y5cyVJR48e1Zw5c9SrVy/l5uaqadOmFarhqSNUFXked74Jz97HcmFhYW73cW69ix3lcVVubq7KysqUlJTk8jvUC+1jTk5OpX4xe6Mbb7xRv/76q8aNG6eOHTsqODi4ultSgwYN1Lt3b8c77969e6t+/fqVqjllyhR169atUtebePrnsjx4lJaWOn45uHKBsCtBLTw8vMJ1y7/3i4uLNX36dPn5+SkxMbHC258tMTFRvXv31qZNm/TZZ585Avhrr73m0gXy3qply5a67bbbtGjRInXt2lXff/+9Nm3apPHjx1e4RteuXVVcXKwtW7bo6NGj+stf/qIGDRqoS5cuevTRR3Xy5EllZWXp2muvdfk6ukWLFqlmzZrau3evfv75Z11zzTUu7qGz8PBw/eMf/9CqVasqfRPFM888o+zsbOXm5qp27dqVqiVxhKjSFi5cqNOnTysqKkp+fn7y8/PT3Llz9e6776qwsNCtmrVq1VKzZs3UrFkz3XLLLXrttddUXFysV199tcI1mjdvLpvNpm+//datHipq165dLl+8LDnvY/lSmUB0br2GDRu6tH2zZs1ks9m0e/dup/Frr71WzZo1O+/dszs9NWvWTI0aNXK5jrdr1KiRsrKydPDgQfXs2VPHjh2r7pYk/fHOu/zowoABAypdr3PnzkpISFBaWprL25Z/f+3ateuC63ft2qW6deu6/G45Li5O27dv1549e/T7779r6dKlbr0Z+LOg5urprvLv/bZt22rRokXKycnRwoULXe6rXGBgoHr06KExY8Zo8+bNeuSRR9w+WucJISEhF3x9LygoqPBRnbOlpKTo3Xff1bFjx7R48WJdd9116tKlS4W3b9asmRo3bqz169dr/fr1jm2joqIUHR2tzZs3a/369S4dPZSkzZs3a/r06UpPT1fHjh2VkpLikVBf/ruyMt588029+OKLevPNN9W8efNK9yQRiCrl9OnTWrZsmV566SVt377dsXz55ZeKioqq1F1TZ7PZbPLx8XG6a+bPhIWFKSEhQbNnz1ZxcfF569297fts69at09dff+32Oz9vUq9ePfXo0UOvvPLKBb9euLSmTZtqw4YNstvtXhOKevbsqVOnTqm0tPSCt/u644UXXtAHH3yg7Oxsl7Yr//6aM2fOeT/Hdrtdy5cv1wMPPODy0dby4NGkSRO3fsFUJKg1aNCgUtcc+vj46JlnntHo0aNdeg27lNatW1frz2mLFi20bdu288a3bdumv/zlLy7Xu//+++Xj46MVK1Zo2bJlGjBggMvfC3FxccrKylJWVpbT2YnOnTtr9erVys3Ndel02YkTJ/TII49o8ODBiouL08KFC5Wbm6t58+a51NflsH37dqWkpOiFF17w2M+2RCCqlPT0dB09elQpKSm64YYbnJbExES33xGVlJTIbrfLbrdr165dGjp0qI4fP667777bpTqzZ8/WmTNn1LFjR7377rvas2ePdu3apZkzZyo2Ntatng4ePKht27Zp0qRJ6tu3r/r06aOHH37YpVpn1zt7+fXXX12u40lz5szR6dOn1aFDB7311lvatWuXdu/erddff13ffvutfH19q7U/bxcdHa2srCzl5+crISFBRUVFLtcoLCx0enOxfft2HThwwK1+fH19tWvXLu3cudNj/3dt2rRRUlKSZs6c6fK2r7zyikpKSpSQkKCNGzfqwIEDysjIUI8ePdSoUSNNnDjRIz26oiJBzROnpe677z75+vpq9uzZLm3322+/qVu3bnr99df11Vdfae/evXr77bc1depU9e3bt9J9uWvw4MH67rvv9Pjjj+urr77S7t279fLLL+uNN95w6+MmgoOD9cADDygtLU2HDx9262seFxenTz75RNu3b3c6utSlSxfNnz9fp06dcikQpaWlybIsx2dwXXPNNXrxxRc1cuRIt64b9ZRff/1V/fr1U9euXfXggw+e93vE3evwJHHbfWX06dPHuuuuuy64Licnx5Jkffnlly7VTE5OtiQ5ltq1a1u33HKL9c4777jV46FDh6zU1FSradOmlr+/v9WoUSPrf/7nf5xuxXSlJz8/P6tBgwZWfHy8tWjRIuvMmTMu93TuPpYvLVq0cLlWeT1P3Yp+6NAha8iQIVZMTIxVo0YNKzg42OrYsaM1bdo0q7i4uNI9edNt9w899JCVmJhYqRoX6ufnn3+2mjdvbt16661WYWGhS7Uu9H2RkpJSqX7O5s5t9+fW27t3r+Xv7+/ybfeWZVn79u2zkpOTrYiICKtGjRpWdHS0NXToUOvXX391uZanvhe+++47q379+tZf//pXa8OGDdb+/fut1atXWzfccIPVrl0769ixYx7pa/LkyVaDBg0u+rEWF3Ly5Enr6aeftm6++WYrNDTUqlmzptWiRQtr9OjR5318QUV54rZ7y7Ks3Nxcq0ePHlaDBg2s0NBQq1OnTtbKlSvdrrd582ZL0kV/p/yZvXv3WpKsli1bOo3v27fP5dfXrKwsy9fX19q0adN56+68806rW7duLn0MybnGjRtntW3b1q1tlyxZcsHXifKladOmbvdls6wquvoWgFfp2bOnmjVrpldeeaW6W0E127dvn5599lllZGQoPz9flmXp3nvv1f/+7/+qZs2a1d0eUCU4ZQYY5ujRo0pPT1dWVpbi4+Orux14gWuuuUZLliyR3W5XWVmZxo4dqzVr1lxVt7cDf4YjRIBh7rnnHm3ZskXJycl6/vnn+cBJXNDixYtVWFioxx9/3KXPQAOuVAQiAABgPGI/AAAwHoEIAAAYj0AEAACMRyACAADGIxABAADjEYgAAIDxCEQAAMB4BCIAAGA8AhEAADDe/wcckGLHoelnnAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "sns.countplot(x = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0d5800f-4a57-425f-b321-122a44ed9529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e7eb38-6ec1-46aa-b3c1-7846057fbd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(np.unique(unique_val))\n",
    "num_epochs = 100\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ca369d5-a732-4202-9080-e9691b62975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = train['label'].tolist()\n",
    "y_train = [ord(label) - ord('A') for label in l]\n",
    "x_train = []\n",
    "for i, row in train.iterrows():\n",
    "    features = row.drop('label').values\n",
    "    x_train.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08959bb1-1c06-466e-aeb6-c2175891e87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = test['label'].tolist()\n",
    "y_test = [ord(label) - ord('A') for label in l]\n",
    "x_test = []\n",
    "for i, row in test.iterrows():\n",
    "    features = row.drop('label').values\n",
    "    x_test.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bf95269-38ac-4620-ae48-0e2a1f0b95c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4b6037c-1a56-43cd-8414-341873596f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train, dtype='float32')\n",
    "x_test = np.array(x_test, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a1df1f1-d22a-45d2-8d00-3a15cde28605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21975, 26)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0a796c3-4196-4b53-811a-a82c59d99243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 26)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b66e6a2-2e30-4d72-86a4-78b18b1595b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 63)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7396302-8541-41a6-8b4a-78276c5304c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=256, activation='relu', input_shape=(63,)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf4429ec-89b4-4f99-9476-4c568ed3d726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 256)               16384     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 26)                1690      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59226 (231.35 KB)\n",
      "Trainable params: 59226 (231.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22a6ee71-abdd-42b5-a930-a9a09ae90755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "172/172 [==============================] - 2s 4ms/step - loss: 3.0300 - accuracy: 0.1093 - val_loss: 1.7867 - val_accuracy: 0.5333\n",
      "Epoch 2/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.7570 - accuracy: 0.4111 - val_loss: 0.5304 - val_accuracy: 0.9333\n",
      "Epoch 3/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 1.0999 - accuracy: 0.6131 - val_loss: 0.2723 - val_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.8315 - accuracy: 0.7030 - val_loss: 0.2143 - val_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6982 - accuracy: 0.7570 - val_loss: 0.1822 - val_accuracy: 0.8667\n",
      "Epoch 6/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.7831 - val_loss: 0.1379 - val_accuracy: 0.9333\n",
      "Epoch 7/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.5443 - accuracy: 0.8116 - val_loss: 0.1004 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.8318 - val_loss: 0.1207 - val_accuracy: 0.9333\n",
      "Epoch 9/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.8433 - val_loss: 0.1286 - val_accuracy: 0.9333\n",
      "Epoch 10/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.4184 - accuracy: 0.8565 - val_loss: 0.0389 - val_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.3898 - accuracy: 0.8688 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.3681 - accuracy: 0.8813 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.3556 - accuracy: 0.8815 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.3281 - accuracy: 0.8950 - val_loss: 0.0349 - val_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8957 - val_loss: 0.0339 - val_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.9025 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.2936 - accuracy: 0.9049 - val_loss: 0.0271 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.9079 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.2771 - accuracy: 0.9116 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.2621 - accuracy: 0.9157 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.2648 - accuracy: 0.9163 - val_loss: 0.0097 - val_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.2423 - accuracy: 0.9213 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "172/172 [==============================] - 1s 3ms/step - loss: 0.2428 - accuracy: 0.9246 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.2382 - accuracy: 0.9235 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.2223 - accuracy: 0.9279 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.2394 - accuracy: 0.9213 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.2295 - accuracy: 0.9291 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9347 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.2102 - accuracy: 0.9343 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.9357 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9391 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.2055 - accuracy: 0.9360 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1967 - accuracy: 0.9395 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9407 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9423 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1892 - accuracy: 0.9422 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1787 - accuracy: 0.9452 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1899 - accuracy: 0.9418 - val_loss: 9.5264e-04 - val_accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1656 - accuracy: 0.9489 - val_loss: 9.1187e-04 - val_accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1885 - accuracy: 0.9410 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1753 - accuracy: 0.9492 - val_loss: 9.3945e-04 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1643 - accuracy: 0.9500 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1760 - accuracy: 0.9463 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1687 - accuracy: 0.9489 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1640 - accuracy: 0.9484 - val_loss: 7.8060e-04 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.9507 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1658 - accuracy: 0.9510 - val_loss: 6.6554e-04 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1545 - accuracy: 0.9525 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1613 - accuracy: 0.9521 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1627 - accuracy: 0.9519 - val_loss: 5.2052e-04 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1522 - accuracy: 0.9551 - val_loss: 5.3793e-04 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1507 - accuracy: 0.9529 - val_loss: 8.0613e-04 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1531 - accuracy: 0.9540 - val_loss: 8.8440e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1509 - accuracy: 0.9544 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.9570 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1439 - accuracy: 0.9554 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9556 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9569 - val_loss: 8.6698e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1534 - accuracy: 0.9546 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1399 - accuracy: 0.9584 - val_loss: 3.2030e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1424 - accuracy: 0.9549 - val_loss: 8.0788e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1432 - accuracy: 0.9582 - val_loss: 5.0922e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9577 - val_loss: 4.9559e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.9590 - val_loss: 3.7736e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9573 - val_loss: 5.1213e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1331 - accuracy: 0.9587 - val_loss: 3.1493e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1329 - accuracy: 0.9614 - val_loss: 6.2670e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1235 - accuracy: 0.9625 - val_loss: 6.1453e-05 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1254 - accuracy: 0.9616 - val_loss: 1.6370e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9582 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9592 - val_loss: 4.5531e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1326 - accuracy: 0.9613 - val_loss: 6.2225e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9602 - val_loss: 3.7447e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.9615 - val_loss: 3.9915e-05 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1433 - accuracy: 0.9560 - val_loss: 2.1034e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9603 - val_loss: 3.0950e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9634 - val_loss: 2.1619e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9666 - val_loss: 2.8546e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9607 - val_loss: 9.2963e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9610 - val_loss: 1.5170e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1260 - accuracy: 0.9610 - val_loss: 3.6019e-05 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9643 - val_loss: 2.6726e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9614 - val_loss: 3.0255e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9665 - val_loss: 5.0163e-05 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1413 - accuracy: 0.9593 - val_loss: 8.9034e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1258 - accuracy: 0.9635 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9656 - val_loss: 1.8774e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9646 - val_loss: 1.8118e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1097 - accuracy: 0.9674 - val_loss: 1.6859e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1246 - accuracy: 0.9639 - val_loss: 4.5975e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1201 - accuracy: 0.9639 - val_loss: 1.7999e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1158 - accuracy: 0.9648 - val_loss: 8.3989e-05 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1130 - accuracy: 0.9673 - val_loss: 4.6030e-05 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.9666 - val_loss: 3.9978e-05 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1193 - accuracy: 0.9649 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1150 - accuracy: 0.9661 - val_loss: 1.2273e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.9635 - val_loss: 3.4750e-05 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9634 - val_loss: 3.3239e-05 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "172/172 [==============================] - 0s 3ms/step - loss: 0.1131 - accuracy: 0.9667 - val_loss: 1.9517e-05 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "172/172 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9694 - val_loss: 1.1382e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x175b7460750>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c691bc5-5e0a-47e0-a06d-44e119f77beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
